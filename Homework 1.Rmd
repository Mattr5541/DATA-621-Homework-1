---
title: "621 - Homework 1"
output:
  pdf_document: default
  html_document:
    df_print: paged
date: "2024-02-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(knitr)
library(readr)
library(ggplot2)
library(tidyverse)
library(missMethods)
library(dplyr)
library(naniar)
library(MASS)
library(ggfortify)
library(glmnet)
library(ggpubr)
library(corrplot)

set.seed(621)
```

```{r, echo = FALSE}
money_train <- read.csv(url("https://raw.githubusercontent.com/Mattr5541/DATA-621-Homework-1/main/moneyball-training-data.csv"))


summary(money_train)
```

## Part 1: Data Exploration
The money training dataset contains 2,276 variables and 17 elements, including the INDEX or identifying variable, TARGET_WINS, the response variable, and 15 explanatory variables. The variable types are numeric values represented as integers. Six variables have missing values and will be imputed in part two. The variable with the most missing variables is TEAM_BATTING_HBP (batters hit by pitch). 

```{r, echo = FALSE}
dim(money_train)
```
```{r, echo = FALSE}
colSums(is.na(money_train))
```
The summary data also states the mean and median for reference, many variables have  similar values, and when the mean and median are very different it suggests the dataset is skewed. The Box plots below visualize these values and show the spread of the data. The boxplots also show many outliers in most of the variables. Additionally, histogram charts can be used to view the skewness of the variables. Both these visuals confirm that the response variable seems to have a normal distribution. While, many variables seem to have a right skew, and some have a bimodal distribution. 

```{r, echo = FALSE}
#box plot not including the index column
money_train %>%
  gather(variable, value, TARGET_WINS:TEAM_FIELDING_DP) %>%
  ggplot(., aes(x= variable, y=value)) + 
  geom_boxplot() +
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())
```

```{r, echo = FALSE}
money_train %>%
  keep(is.numeric) %>%                     
  gather(key, value, TARGET_WINS:TEAM_FIELDING_DP) %>%                             
  ggplot(aes(value)) +                     
    facet_wrap(~ key, scales = "free") +  
    geom_histogram(bins = 35)           
```
The target variable is the response variable 'TARGET_WINS'. The scatter plots below show the visual of all other variables, the spread of their data and the correlation line to observe the relationship to the target variable. The sorted_correlation lists the correlation metrics from highest to lowest, indicating these variables are the most positively correlated with results of .46 or above TEAM_PITCHING_H, TEAM_BATTING_H, TEAM_BATTING_BB, and TEAM_PITCHING_BB. To assess if variables are correlated to other variables in the dataset a correlation matrix, with the coefficients added, is also shown below. This will come in handy when trying to avoid collinearity.  

```{r, echo = FALSE}
money_train <- money_train[, -1]
money_train %>% 
  gather(variable, value, -TARGET_WINS) %>%
  ggplot(., aes(value, TARGET_WINS)) + 
  geom_point(fill = "blue", color="blue") + 
  geom_smooth(method = "lm", se = FALSE, color = "black") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = "Wins") 
```
```{r, echo = FALSE}
# sorted correlation of explanatory variables correlated to TARGET_WINS, response variables. 
correlation_matrix <- cor(drop_na(money_train))
correlation_coefficients <- correlation_matrix[, 1]
sorted_correlation <- sort(correlation_coefficients, decreasing = TRUE)
print(sorted_correlation)

```
```{r, echo = FALSE}
correlation_matrix <- cor(drop_na(money_train))
corrplot(correlation_matrix, method = "color", 
         addgrid.col = NA, tl.col = "black", tl.srt = 45,
         addCoef.col = "black",
         tl.cex = 0.5,
         number.cex = 0.5) 
```


## Part 2: Median Imputations for missing variables

To compensate for missingness, we will perform a simple median imputation. We will use the median instead of the mean as some variables in this dataset are heavily skewed.

```{r, echo = FALSE}
## Vars with missing observations include: TEAM_BATTING_SO; TEAM_BASERUN_SB; TEAM_BASERUN_CS; TEAM_BATTING_HBP; TEAM_PITCHING_SO; TEAM_FIELDING_DP
###Team_BATTING_HBP contains over 2000 missing variables; everything else is within the range of 102-772

####First, I will make indices to flag missing values 
TEAM_BATTING_SO_index <- is.na(money_train$TEAM_BATTING_SO)  
TEAM_BASERUN_SB_index <- is.na(money_train$TEAM_BASERUN_SB) 
TEAM_BASERUN_CS_index <- is.na(money_train$TEAM_BASERUN_CS) 
TEAM_BATTING_HBP_index <- is.na(money_train$TEAM_BATTING_HBP) 
TEAM_PITCHING_SO_index <- is.na(money_train$TEAM_PITCHING_SO) 
TEAM_FIELDING_DP_index <- is.na(money_train$TEAM_FIELDING_DP) 


### And now to impute

money_train_mod <- money_train %>% missMethods::impute_median()
summary(money_train_mod)

money_train <- money_train %>% mutate(INDEX = seq_len(nrow(money_train)))
money_train_mod <- money_train_mod %>% mutate(INDEX = seq_len(nrow(money_train_mod)))

### Now I will compare some variables to see if the median imputation worked
money_train_comp <- money_train$TEAM_BATTING_SO

money_train_comp <- money_train %>% dplyr::select(INDEX, TEAM_BATTING_SO, TEAM_BASERUN_SB, TEAM_BATTING_HBP, TEAM_BASERUN_CS, TEAM_PITCHING_SO, TEAM_FIELDING_DP)
money_train_mod_comp <- money_train_mod %>% dplyr::select(INDEX, TEAM_BATTING_SO, TEAM_BASERUN_SB, TEAM_BATTING_HBP, TEAM_BASERUN_CS, TEAM_PITCHING_SO,  TEAM_FIELDING_DP)

money_train_index <- cbind(TEAM_BATTING_SO_index, TEAM_BASERUN_SB_index, TEAM_BASERUN_CS_index, TEAM_BATTING_HBP_index, TEAM_PITCHING_SO_index, TEAM_FIELDING_DP_index)
money_train_index <- as.data.frame(money_train_index)
  
money_train_comp <- merge(money_train_comp, money_train_mod_comp, by = "INDEX")
money_train_comp <- money_train_comp %>% cbind(money_train_index)


ggplot(money_train_comp, aes(TEAM_BATTING_SO.y, color = TEAM_BATTING_SO_index)) + geom_histogram()
ggplot(money_train_comp, aes(TEAM_BASERUN_SB.y, color = TEAM_BASERUN_SB_index)) + geom_histogram()
ggplot(money_train_comp, aes(TEAM_BASERUN_CS.y, color = TEAM_BASERUN_CS_index)) + geom_histogram()
ggplot(money_train_comp, aes(TEAM_BATTING_HBP.y, color = TEAM_BATTING_HBP_index)) + geom_histogram() ##As we can see, this mean imputation method may not have 
##been entirely appropriate for this variable, since such a large proportion was missing (~88%). Everything else should be fine.
ggplot(money_train_comp, aes(TEAM_PITCHING_SO.y, color = TEAM_PITCHING_SO_index)) + geom_histogram()
ggplot(money_train_comp, aes(TEAM_FIELDING_DP.y, color = TEAM_FIELDING_DP_index)) + geom_histogram()


```

The imputation was a success for the most part, as most variables were not heavily affected in terms of their distributions. However, the TEAM_BATTING_HBP variable was heavily modified following the imputation, as \~88% of its observations were missing. As a result, we will not use this variable in our upcoming predictive tests

### Investigate whether the assumptions for linear regression have been met for each variable

```{r, echo = FALSE}
##TARGET_WINS
q1 <- ggplot(money_train_mod, aes(sample = TARGET_WINS)) + stat_qq() + stat_qq_line() + labs(title = "TARGET_WINS")

##TEAM_BATTING_H
q2 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_H)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_H")

##TEAM_BATTING_2B 
q3 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_2B)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_2B")

##TEAM_BATTING_3B 
q4 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_3B)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_3B")

##TEAM_BATTING_HR 
q5 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_HR)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_HR")

##TEAM_BATTING_BB
q6 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_BB)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_BB")

##TEAM_BATTING_SO
q7 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_SO)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_SO")

ggarrange(q1, q2, q3, q4, q5, q6, q7)

```

```{r, echo = FALSE}
par(mfrow=c(3,3))
hist(money_train_mod$TARGET_WINS, main = "TARGET_WINS") #Appears mostly normal with some potential skew
hist(money_train_mod$TEAM_BATTING_H, main ="TEAM_BATTING_H") #Positive skew is apparant
hist(money_train_mod$TEAM_BATTING_2B, main ="TEAM_BATTING_2B") #Appears mostly normal
hist(money_train_mod$TEAM_BATTING_3B, main ="TEAM_BATTING_3B") #Positive skew apparant
hist(money_train_mod$TEAM_BATTING_HR, main ="TEAM_BATTING_HR") #Does not seem normally distributed
hist(money_train_mod$TEAM_BATTING_BB, main ="TEAM_BATTING_BB") # Negative skew apparant
hist(money_train_mod$TEAM_BATTING_SO, main ="TEAM_BATTING_SO") # Seems platykurtic
hist(money_train_mod$TEAM_BASERUN_SB, main ="TEAM_BASERUN_SB") #Positive skew apparant
hist(money_train_mod$TEAM_BASERUN_CS, main ="TEAM_BASERUN_CS") #Positive skew apparant
hist(money_train_mod$TEAM_BATTING_HBP, main ="TEAM_BATTING_HBP") #Issues derived from imputation
hist(money_train_mod$TEAM_PITCHING_H, main ="TEAM_PITCHING_H") #Heavy positive skew apparant
hist(money_train_mod$TEAM_PITCHING_HR, main ="TEAM_PITCHING_HR") #Data do not seem normally distributed
hist(money_train_mod$TEAM_PITCHING_BB, main ="TEAM_PITCHING_BB") #Heavy positive skew apparant
hist(money_train_mod$TEAM_PITCHING_SO, main ="TEAM_PITCHING_SO") #Heavy positive skew apparant
hist(money_train_mod$TEAM_FIELDING_E, main ="TEAM_FIELDING_E") #Heavy positive skew apparant
hist(money_train_mod$TEAM_FIELDING_DP, main ="TEAM_FIELDING_DP") #Some negative skew apparant
```
Following our imputation, we can see that some variables are either lightly or heavily skewed. In order to correct for this, we will perform log transformations in an attempt to normalize the variables.

### Correlation plots following imputation to test for collinearity among variables

```{r, echo = FALSE}
cor <- cor(money_train_mod)

cor <- as.data.frame(cor)

cor <- cor %>% mutate_all(~ ifelse(abs(.) < 0.5, NA, .))

print(cor)
```

Most of the variables are not highly correlated, but there are some potential predictors that are \~ 50-60% correlated. Most concerningly would be the \~90% correlation between TEAM_PITCHING_HR and TEAM_BATTING_HR. Because of the very high correlation between these variables, it may be best to avoid using them in the same model. Otherwise, it may be necessary to transform the variables via mean centering or PCA.

### Log Transformations

Because some variables are heavily affected by negative skew, we can systematically remove outliers that are present

```{r, echo = FALSE}
# Apply log transformations; and safely by add 1 to avoid log(0) in variables with 0's
money_train_mod <- money_train_mod %>% mutate(log_TEAM_FIELDING_E = log(TEAM_FIELDING_E))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_PITCHING_H = log(TEAM_PITCHING_H))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_PITCHING_BB = log(TEAM_PITCHING_BB))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_PITCHING_SO = log(TEAM_PITCHING_SO))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BASERUN_SB = log(TEAM_BASERUN_SB))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BATTING_3B = log(TEAM_BATTING_3B))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BATTING_HR = log(TEAM_BATTING_HR))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BATTING_SO = log(TEAM_BATTING_SO))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BASERUN_CS = log(TEAM_BASERUN_CS))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_FIELDING_DP = log(TEAM_FIELDING_DP))
money_train_mod$log_TEAM_BASERUN_CS <- log(money_train_mod$TEAM_BASERUN_CS + 1)
money_train_mod$log_TEAM_BATTING_HR <- log(money_train_mod$TEAM_BATTING_HR + 1)
money_train_mod$log_TEAM_BATTING_SO <- log(money_train_mod$TEAM_BATTING_SO + 1)
money_train_mod$log_TEAM_BATTING_3B <- log(money_train_mod$TEAM_BATTING_3B + 1)
money_train_mod$log_TEAM_BASERUN_SB <- log(money_train_mod$TEAM_BASERUN_SB + 1)
money_train_mod$log_TEAM_PITCHING_SO <- log(money_train_mod$TEAM_PITCHING_SO + 1)
money_train_mod$log_TEAM_FIELDING_E <- log(money_train_mod$TEAM_FIELDING_E + 1)
money_train_mod$log_TEAM_PITCHING_BB <- log(money_train_mod$TEAM_PITCHING_BB + 1)


par(mfrow=c(3,3))
hist(money_train_mod$log_TEAM_FIELDING_E, main = "log_TEAM_FIELDING_E")
hist(money_train_mod$log_TEAM_PITCHING_H, main = "log_TEAM_PITCHING_H")
hist(money_train_mod$log_TEAM_PITCHING_BB, main = "log_TEAM_PITCHING_BB")
hist(money_train_mod$log_TEAM_PITCHING_SO, main = "log_TEAM_PITCHING_SO")
hist(money_train_mod$TEAM_BASERUN_CS, main = "TEAM_BASERUN_CS")
hist(money_train_mod$TEAM_BATTING_SO, main = "TEAM_BATTING_SO")
hist(money_train_mod$TEAM_BATTING_BB, main = "TEAM_BATTING_BB")
hist(money_train_mod$TEAM_BATTING_3B, main = "TEAM_BATTING_3B")

```

## Part 3 – Building the Models

### Model #1 –\> Basic Multiple Linear Regression

For our first model, I decided to go with a basic multiple linear regression. I will choose variables that show the least violations of linear regression assumptions and make sure to keep minimal multicollinearity.

The following is why I chose each variable:

TEAM_BATTING_H –\> Number of hits a team gets increases the chances of them winning... Mostly normally distributed

TEAM_BATTING_BB –\> Greater walks for batting team increases the chances of winning... That means the pitching team does not pitch properly (keep throwing ball instead of strike)

log_TEAM_PITCHING_SO –\> A team that pitches strikeouts might influence winning on the pitching team. Since the log was more normally distributed, I decided to include this one.

log_TEAM_FIELDING_E –\> A pitching team that commits errors more likely to lose,using log because it is more normally distributed.

```{r, echo = FALSE}
###Use a variation of this code if you intend to use a Box-Cox transformation
#boxcox(outcome ~ predictors, data = money_train_mod_2)

model1 = lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_BB + log_TEAM_PITCHING_SO+ log_TEAM_FIELDING_E , data= money_train_mod)

summary(model1)

autoplot(model1)
```

#### Interpreting Coefficients

TEAM_BATTING_H and TEAM_BATTING_BB both had positive coefficients (and statistically significant p-values), which makes sense. As TEAM_BATTING_H and TEAM_BATTING_BB increases, the chances of the batting team winning increases.

This makes sense in baseball world. As a batting team gets more hits, they have more chances of moving around the bases and scoring. Even if the batter hits a foul, as long as they do not get strikes out they can still get a hit and score (you can have 2 strikes and keep hitting fouls and still have a chance of getting a hit.)

The walking makes sense as well. If the pitching team keeps throwing bad pitches (that keep being balls instead of strikes), and the batter has enough skill to not blindly swing at these bad pitches, the batter will walk and go to first base, automatically increasing the chances of them scoring.

log_TEAM_PITCHING_SO has a positive coefficient but has a high p-value. This means that as the log(\# of strike outs the pitching team got) increases, so does the chances of the pitching team winning. This makes sense in terms of baseball. If a team has a good pitcher that throws good strikes, the chances of the other team winning decreases. Sometimes, there are even no-hitter games (where the batting team didn't even get a hit/ all strike outs). However, since the p-value was not significant, this relationship is possibly not as strong in influencing the win of a game.

log_TEAM_FIELDING_E had a negative coefficient and a statistically significant p-value. As log(\# of fielding error) increases, the chances of that team winning decreases. This makes sense in the baseball context. If players on the fields are missing and not catching the ball properly, they give the batting team an advantage and they can score more (AKA pitching team more likely to lose).

### Model #2 –\> Multiple Linear Regression with Interaction Terms

To win in baseball, you need to have BOTH good defense and good offense.

A team can have the best batters/ designated hitters... but what good is that if you have bad pitches/ players that can't throw and catch. You need a good mix of both to win.

In this model, I perform a multiple regression using interaction terms. I am using the same predictors that I used above. Interaction terms in regression models allow us to explore how the effect of one variable on the outcome changes depending on the level of another variable. In the context of baseball, adding interaction terms between offensive and defensive statistics can help quantify the idea that the impact of having strong hitters (offense) on winning games might vary depending on the strength of the team's pitching (defense), and vice versa.

```{r, echo = FALSE}
model2 = lm(TARGET_WINS ~ TEAM_BATTING_H * TEAM_BATTING_BB + log_TEAM_PITCHING_SO* log_TEAM_FIELDING_E , data= money_train_mod)

summary(model2)

autoplot(model2)
```

The coefficient for TEAM_BATTING_H is positive (0.06802), indicating that an increase in team hits is associated with an increase in wins. This makes sense as more hits generally lead to more scoring opportunities.

Similarly, the positive coefficient for TEAM_BATTING_BB suggests that teams that walk more win more. This makes sense.

The negative coefficient for log_TEAM_PITCHING_SO might initially seem counterintuitive, as strikeouts are generally beneficial for pitchers. However, this effect is contextualized by its interaction with fielding errors. The benefits of high strike out number decreases if your team is making alot of errors (and letting the other team score). Even if you have a good pitcher, if your field players aren't good, you will lose.

The negative coefficient for log_TEAM_FIELDING_E aligns with expectations, as more errors typically hurt a team's chances of winning.

Interaction between TEAM_BATTING_H and TEAM_BATTING_BB: The negative term indicates that the positive effect of having more hits or walks on winning games diminishes slightly when both are high. Which means that if a team is already good at hitting, getting better at walks doesn't increase their wins as much as you'd expect.

Interaction between log_TEAM_PITCHING_SO and log_TEAM_FIELDING_E: The positive coefficient means that even though teams that strike out a lot of batters but make many errors might seem at a disadvantage, these errors don't hurt them as much in terms of winning games.

### 

### Model #3

In this model, I add TEAM_BASERUN_SB and TEAM_FIELDING_DP as two additional predictors.

TEAM_BASERUN_SB is number of stolen bases and might influence wins (since players that successfully steal bases are literally closer to scoring).

TEAM_FIELDING_DP tells us the number of double plays (or two outs in one play). Teams that have high numbers of double play are probably good in defense.'

I am also adding interaction terms:

TEAM_BATTING_H and TEAM_BASERUN_SB: explores how the effect of hits on winning is affected by the team's ability to steal bases (aggressive offensive strategy).

TEAM_PITCHING_SO and TEAM_FIELDING_DP: examines how the effect of strikeouts on wins is influenced by the team's ability to execute double plays

```{r, echo = FALSE}
model3 = lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_BASERUN_SB + log_TEAM_FIELDING_DP + log_TEAM_PITCHING_SO + log_TEAM_FIELDING_E + TEAM_BATTING_H:log_TEAM_BASERUN_SB + log_TEAM_PITCHING_SO:log_TEAM_FIELDING_DP, data = money_train_mod)


summary(model3)

autoplot(model3)
```

TEAM_BATTING_H and TEAM_BATTING_BB both had positive coefficients (and statistically significant p-values), which makes sense. As TEAM_BATTING_H and TEAM_BATTING_BB increases, the chances of the batting team winning increases.

This makes sense in baseball world. As a batting team gets more hits, they have more chances of moving around the bases and scoring. Even if the batter hits a foul, as long as they do not get strikes out they can still get a hit and score (you can have 2 strikes and keep hitting fouls and still have a chance of getting a hit.)

The walking makes sense as well. If the pitching team keeps throwing bad pitches (that keep being balls instead of strikes), and the batter has enough skill to not blindly swing at these bad pitches, the batter will walk and go to first base, automatically increasing the chances of them scoring.

The TEAM_BASERUN_SB (stolen bases) predictor had a negative coefficient and was not statistically significant. This means that stolen bases alone do not impact a teams win. This makes sense. You can have increase numbers of stolen bases but that doesn't mean anything. For example, lets say a player steals 2 bases during an inning (and now is on 3rd base). If there is are 3 outs and that inning ends, those stolen bases would have been for nothing (did not lead the batting team closer to winning).

The TEAM_FIELDING_DP (double play) predictor had a negative coefficient and also was not statistically significant. This also means that double play count doesn't really predict a teams ability to win. This kind of makes sense. A team with large double play count for instance might have less strike out count (since the opposing team got more hits that led to those double plays).

log_TEAM_PITCHING_SO has a positive coefficient but has a high p-value. This means that as the log(\# of strike outs the pitching team got) increases, so does the chances of the pitching team winning. This makes sense in terms of baseball. If a team has a good pitcher that throws good strikes, the chances of the other team winning decreases. Sometimes, there are even no-hitter games (where the batting team didn't even get a hit/ all strike outs). However, since the p-value was not significant, this relationship is possibly not as strong in influencing the win of a game.

log_TEAM_FIELDING_E had a negative coefficient and a statistically significant p-value. As log(\# of fielding error) increases, the chances of that team winning decreases. This makes sense in the baseball context. If players on the fields are missing and not catching the ball properly, they give the batting team an advantage and they can score more (AKA pitching team more likely to lose).

The interaction coefficient between TEAM_BASERUN_SB and TEAM_BATTING_H was positive and not significant, meaning hits and stolen bases combined do not impact the wins of this model. This makes sense. In baseball, hits seem more important than stolen bases. Without hits, you can't even steal bases (unless you walk but there has to be an opportunity to steal created).

The interaction coefficient between TEAM_FIELDING_DP and log_TEAM_PITCHING_SO was negative and significant. This means that pitching strikeouts and having alot of double plays contributes to winning. The negative coefficient makes sense. As more strikeouts are pitched, there is less of a chance of the opposing team getting a hit (which decreases your chances of having a double play). After all, double play happens when the batter hits (aka not a strike). But for a team that has less strikeouts, those double plays play an important role in preventing the other team from scoring (which increases your team from winning).

## Part 4: SELECT MODELS

The objective of this project is to build a multiple linear regression model on 
the training data to predict the number of wins for the team. It is ideal to build
a model with a lower level of complexity that can accomplish a higher level of 
accuracy, and if we can achieve a higher level of accuracy with a more complex 
model, that added complexity may be necessary.

In "Part 3" our team created three different models: a Basic Multiple Linear 
Regression, a Multiple Linear Regression with Interaction Terms, and a model that 
took into account a few additional variables (TEAM_BASERUN_SB and TEAM_FIELDING_DP)
with the same basic concepts (Multiple Regression with Interactive Relationships) 
applied in "Model 2."

When looking at the three models predictive metrics, I want to start off with a 
simple AIC (Akaike Information Criterion) comparison. For context, when comparing
models' AIC values, the model with the lowest AIC value is generally the best 
model in terms of "goodness of fit."

```{r, echo = FALSE}
AIC_values <- AIC(model1, model2, model3)

print(AIC_values)
```

After running instance of AIC() on all three models we get a result of very similar
scores with different degrees of freedom. Looking at the instance of AIC() above, 
my initial choice would be to choose Model 3. Model 3 is definitely the most complex
of all the three models ran; however, it also yields the minimum AIC score of the
three models ran in this project.

I also want to go ahead and compare the three models using a BIC comparison (Bayesian
Information Criterion). Similarly to AIC, we are looking for the lowest score,
though we do want to consider the trade-offs presented by model complexity.

```{r, echo = FALSE}
BIC_values <- BIC(model1, model2, model3)

print(BIC_values)
```

Again, similarly to the results yielded using the AIC comparison, Model 3 has the
lowest score.


I do acknowledge that there is an about 15.6% size difference in the number of 
observations, and I also acknowledge that running both AIC and BIC comparisons 
yield a clear favorite in terms of goodness of fit. I will not base my final decision
of model choice based on these metrics and I will use there comparisons to inform
the ultimate decision.

Now, I want to look at the $R^2$ values for the respective models, so that I can 
assess how the models deal with variance present in the data.

```{r, echo = FALSE}
summary(model1)$r.squared
summary(model2)$r.squared
summary(model3)$r.squared
```

When comparing $R^2$ values for the respective models, it is clear that Model 3
yields the best $R^2$ value. However, it is notable that all $R^2$ are rather low, indicating that our models may not be explaining much of the variance in our outcome variable (TARGET_WINS). 

Now, I want to check the RMSE for each model:

```{r, echo = FALSE}
predictions_train_1 = predict(model1, newdata = money_train_mod)
predictions_train_2 = predict(model2, newdata = money_train_mod)
predictions_train_3 = predict(model3, newdata = money_train_mod)

rmse1 = sqrt(mean(predictions_train_1 - money_train_mod$TARGET_WINS)^2)
rmse2 = sqrt(mean(predictions_train_2 - money_train_mod$TARGET_WINS)^2)
rmse3 = sqrt(mean(predictions_train_3 - money_train_mod$TARGET_WINS)^2)

print(rmse1)
print(rmse2)
print(rmse3)
```

Based on these RMSE values, it does not seem that there is a very clear model that
serves as a best predictor. The RMSE values are all at essentially zero, which is 
rather ideal for model performance and when comparing models not super ideal as 
there doesn't seem to be much differentiation when it comes the RMSE metric and 
therefore RMSE does not really point out any particular model as the ideal choice

Considering the results from the comparison of AIC, BIC, R-squared values and RMSE
values, it seems that Model 3 is the best fit. We do understand that model 3 is 
the most complex and with an ideal RMSE, the lowest AIC and BIC scores and the 
highest $R^2$, model 3 seems to be a good choice.

Now, before I check the model's respective performance on the evaluation data, I 
have to prepare my model evaluation data set.

```{r, echo = FALSE}
evaluation = read_csv('https://raw.githubusercontent.com/Mattr5541/DATA-621-Homework-1/main/moneyball-training-data.csv')

money_train_join = money_train %>%
  mutate(train_or_test = 'train')

evaluation_join = evaluation %>%
  mutate(train_or_test = 'test')

df = rbind(subset(money_train_join, select =-TARGET_WINS), evaluation_join)

df <- df %>% 
  missMethods::impute_median() %>%
  filter(train_or_test == 'test')

df <- df %>% mutate(log_TEAM_FIELDING_E = log(TEAM_FIELDING_E))
df <- df %>% mutate(log_TEAM_PITCHING_H = log(TEAM_PITCHING_H))
df <- df %>% mutate(log_TEAM_PITCHING_BB = log(TEAM_PITCHING_BB))
df <- df %>% mutate(log_TEAM_PITCHING_SO = log(TEAM_PITCHING_SO))
df <- df %>% mutate(log_TEAM_BASERUN_SB = log(TEAM_BASERUN_SB))
df <- df %>% mutate(log_TEAM_BATTING_3B = log(TEAM_BATTING_3B))
df <- df %>% mutate(log_TEAM_BATTING_HR = log(TEAM_BATTING_HR))
df <- df %>% mutate(log_TEAM_BATTING_SO = log(TEAM_BATTING_SO))
df <- df %>% mutate(log_TEAM_BASERUN_CS = log(TEAM_BASERUN_CS))
df <- df %>% mutate(log_TEAM_FIELDING_DP = log(TEAM_FIELDING_DP))
df$log_TEAM_BASERUN_CS <- log(df$TEAM_BASERUN_CS + 1)
df$log_TEAM_BATTING_HR <- log(df$TEAM_BATTING_HR + 1)
df$log_TEAM_BATTING_SO <- log(df$TEAM_BATTING_SO + 1)
df$log_TEAM_BATTING_3B <- log(df$TEAM_BATTING_3B + 1)
df$log_TEAM_BASERUN_SB <- log(df$TEAM_BASERUN_SB + 1)
df$log_TEAM_PITCHING_SO <- log(df$TEAM_PITCHING_SO + 1)
df$log_TEAM_FIELDING_E <- log(df$TEAM_FIELDING_E + 1)
df$log_TEAM_PITCHING_BB <- log(df$TEAM_PITCHING_BB + 1)
```

Now, with my test data set prepared, I can run predictions:

#### Model 1 Predictions:

```{r, echo = FALSE}
predictions_1 = predict(model1, newdata = df)

print(predictions_1)
```

#### Model 2 Predictions:

```{r, echo = FALSE}
predictions_2 = predict(model2, newdata = df)

print(predictions_2)
```

#### Model 3 Predictions:

```{r, echo = FALSE}
predictions_3 = predict(model3, newdata = df)

print(predictions_3)
```



# Appendix

## R Code

```{r, results = "hide", fig.keep = "none"}
library(knitr)
library(readr)
library(ggplot2)
library(tidyverse)
library(missMethods)
library(dplyr)
library(naniar)
library(MASS)
library(ggfortify)
library(glmnet)
library(ggpubr)
library(corrplot)

set.seed(621)

###Import and Summarize the data
money_train <- read.csv(url("https://raw.githubusercontent.com/Mattr5541/DATA-621-Homework-1/main/moneyball-training-data.csv"))


summary(money_train)

###Descriptive data analysis
dim(money_train)
colSums(is.na(money_train))
#box plot not including the index column

money_train %>%
  gather(variable, value, TARGET_WINS:TEAM_FIELDING_DP) %>%
  ggplot(., aes(x= variable, y=value)) + 
  geom_boxplot() +
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())

money_train %>%
  keep(is.numeric) %>%                     
  gather(key, value, TARGET_WINS:TEAM_FIELDING_DP) %>%                             
  ggplot(aes(value)) +                     
    facet_wrap(~ key, scales = "free") +  
    geom_histogram(bins = 35)    

money_train <- money_train[, -1]
money_train %>% 
  gather(variable, value, -TARGET_WINS) %>%
  ggplot(., aes(value, TARGET_WINS)) + 
  geom_point(fill = "blue", color="blue") + 
  geom_smooth(method = "lm", se = FALSE, color = "black") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = "Wins") 

# sorted correlation of explanatory variables correlated to TARGET_WINS, response variables. 
correlation_matrix <- cor(drop_na(money_train))
correlation_coefficients <- correlation_matrix[, 1]
sorted_correlation <- sort(correlation_coefficients, decreasing = TRUE)
print(sorted_correlation)

correlation_matrix <- cor(drop_na(money_train))
corrplot(correlation_matrix, method = "color", 
         addgrid.col = NA, tl.col = "black", tl.srt = 45,
         addCoef.col = "black",
         tl.cex = 0.5,
         number.cex = 0.5) 

###Imputation and testing the imputation
## Vars with missing observations include: TEAM_BATTING_SO; TEAM_BASERUN_SB; TEAM_BASERUN_CS; TEAM_BATTING_HBP; TEAM_PITCHING_SO; TEAM_FIELDING_DP
###Team_BATTING_HBP contains over 2000 missing variables; everything else is within the range of 102-772

####First, I will make indices to flag missing values 
TEAM_BATTING_SO_index <- is.na(money_train$TEAM_BATTING_SO)  
TEAM_BASERUN_SB_index <- is.na(money_train$TEAM_BASERUN_SB) 
TEAM_BASERUN_CS_index <- is.na(money_train$TEAM_BASERUN_CS) 
TEAM_BATTING_HBP_index <- is.na(money_train$TEAM_BATTING_HBP) 
TEAM_PITCHING_SO_index <- is.na(money_train$TEAM_PITCHING_SO) 
TEAM_FIELDING_DP_index <- is.na(money_train$TEAM_FIELDING_DP) 


### And now to impute

money_train_mod <- money_train %>% missMethods::impute_median()
summary(money_train_mod)

money_train <- money_train %>% mutate(INDEX = seq_len(nrow(money_train)))
money_train_mod <- money_train_mod %>% mutate(INDEX = seq_len(nrow(money_train_mod)))

### Now I will compare some variables to see if the median imputation worked
money_train_comp <- money_train$TEAM_BATTING_SO

data.frame(money_train_comp)

money_train_comp <- money_train %>% dplyr::select(INDEX, TEAM_BATTING_SO, TEAM_BASERUN_SB, TEAM_BATTING_HBP, TEAM_BASERUN_CS, TEAM_PITCHING_SO, TEAM_FIELDING_DP)
money_train_mod_comp <- money_train_mod %>% dplyr::select(INDEX, TEAM_BATTING_SO, TEAM_BASERUN_SB, TEAM_BATTING_HBP, TEAM_BASERUN_CS, TEAM_PITCHING_SO,  TEAM_FIELDING_DP)

money_train_index <- cbind(TEAM_BATTING_SO_index, TEAM_BASERUN_SB_index, TEAM_BASERUN_CS_index, TEAM_BATTING_HBP_index, TEAM_PITCHING_SO_index, TEAM_FIELDING_DP_index)
money_train_index <- as.data.frame(money_train_index)
  
money_train_comp <- merge(money_train_comp, money_train_mod_comp, by = "INDEX")
money_train_comp <- money_train_comp %>% cbind(money_train_index)


ggplot(money_train_comp, aes(TEAM_BATTING_SO.y, color = TEAM_BATTING_SO_index)) + geom_histogram()
ggplot(money_train_comp, aes(TEAM_BASERUN_SB.y, color = TEAM_BASERUN_SB_index)) + geom_histogram()
ggplot(money_train_comp, aes(TEAM_BASERUN_CS.y, color = TEAM_BASERUN_CS_index)) + geom_histogram()
ggplot(money_train_comp, aes(TEAM_BATTING_HBP.y, color = TEAM_BATTING_HBP_index)) + geom_histogram() ##As we can see, this mean imputation method may not have 
##been entirely appropriate for this variable, since such a large proportion was missing (~88%). Everything else should be fine.
ggplot(money_train_comp, aes(TEAM_PITCHING_SO.y, color = TEAM_PITCHING_SO_index)) + geom_histogram()
ggplot(money_train_comp, aes(TEAM_FIELDING_DP.y, color = TEAM_FIELDING_DP_index)) + geom_histogram()

###QQ plots and histograms of imputed data
##TARGET_WINS
q1 <- ggplot(money_train_mod, aes(sample = TARGET_WINS)) + stat_qq() + stat_qq_line() + labs(title = "TARGET_WINS")

##TEAM_BATTING_H
q2 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_H)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_H")

##TEAM_BATTING_2B 
q3 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_2B)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_2B")

##TEAM_BATTING_3B 
q4 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_3B)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_3B")

##TEAM_BATTING_HR 
q5 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_HR)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_HR")

##TEAM_BATTING_BB
q6 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_BB)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_BB")

##TEAM_BATTING_SO
q7 <- ggplot(money_train_mod, aes(sample = TEAM_BATTING_SO)) + stat_qq() + stat_qq_line() + labs(title = "TEAM_BATTING_SO")

ggarrange(q1, q2, q3, q4, q5, q6, q7)


### Log transformations and histograms of log transformations

# Apply log transformations; and safely by add 1 to avoid log(0) in variables with 0's
money_train_mod <- money_train_mod %>% mutate(log_TEAM_FIELDING_E = log(TEAM_FIELDING_E))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_PITCHING_H = log(TEAM_PITCHING_H))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_PITCHING_BB = log(TEAM_PITCHING_BB))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_PITCHING_SO = log(TEAM_PITCHING_SO))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BASERUN_SB = log(TEAM_BASERUN_SB))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BATTING_3B = log(TEAM_BATTING_3B))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BATTING_HR = log(TEAM_BATTING_HR))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BATTING_SO = log(TEAM_BATTING_SO))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_BASERUN_CS = log(TEAM_BASERUN_CS))
money_train_mod <- money_train_mod %>% mutate(log_TEAM_FIELDING_DP = log(TEAM_FIELDING_DP))
money_train_mod$log_TEAM_BASERUN_CS <- log(money_train_mod$TEAM_BASERUN_CS + 1)
money_train_mod$log_TEAM_BATTING_HR <- log(money_train_mod$TEAM_BATTING_HR + 1)
money_train_mod$log_TEAM_BATTING_SO <- log(money_train_mod$TEAM_BATTING_SO + 1)
money_train_mod$log_TEAM_BATTING_3B <- log(money_train_mod$TEAM_BATTING_3B + 1)
money_train_mod$log_TEAM_BASERUN_SB <- log(money_train_mod$TEAM_BASERUN_SB + 1)
money_train_mod$log_TEAM_PITCHING_SO <- log(money_train_mod$TEAM_PITCHING_SO + 1)
money_train_mod$log_TEAM_FIELDING_E <- log(money_train_mod$TEAM_FIELDING_E + 1)
money_train_mod$log_TEAM_PITCHING_BB <- log(money_train_mod$TEAM_PITCHING_BB + 1)


par(mfrow=c(3,3))
hist(money_train_mod$log_TEAM_FIELDING_E, main = "log_TEAM_FIELDING_E")
hist(money_train_mod$log_TEAM_PITCHING_H, main = "log_TEAM_PITCHING_H")
hist(money_train_mod$log_TEAM_PITCHING_BB, main = "log_TEAM_PITCHING_BB")
hist(money_train_mod$log_TEAM_PITCHING_SO, main = "log_TEAM_PITCHING_SO")
hist(money_train_mod$TEAM_BASERUN_CS, main = "TEAM_BASERUN_CS")
hist(money_train_mod$TEAM_BATTING_SO, main = "TEAM_BATTING_SO")
hist(money_train_mod$TEAM_BATTING_BB, main = "TEAM_BATTING_BB")
hist(money_train_mod$TEAM_BATTING_3B, main = "TEAM_BATTING_3B")


###Multiple Regression models

model1 = lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_BB + log_TEAM_PITCHING_SO+ log_TEAM_FIELDING_E , data= money_train_mod)

summary(model1)

autoplot(model1)

model2 = lm(TARGET_WINS ~ TEAM_BATTING_H * TEAM_BATTING_BB + log_TEAM_PITCHING_SO* log_TEAM_FIELDING_E , data= money_train_mod)

summary(model2)

autoplot(model2)

model3 = lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_BASERUN_SB + log_TEAM_FIELDING_DP + log_TEAM_PITCHING_SO + log_TEAM_FIELDING_E + TEAM_BATTING_H:log_TEAM_BASERUN_SB + log_TEAM_PITCHING_SO:log_TEAM_FIELDING_DP, data = money_train_mod)


summary(model3)

autoplot(model3)

###Model validation via AIC and BIC criteria
AIC_values <- AIC(model1, model2, model3)

print(AIC_values)

BIC_values <- BIC(model1, model2, model3)

print(BIC_values)

###Comparing R^2 values
summary(model1)$r.squared
summary(model2)$r.squared
summary(model3)$r.squared

###Predictive modeling and checking the RMSE
predictions_train_1 = predict(model1, newdata = money_train_mod)
predictions_train_2 = predict(model2, newdata = money_train_mod)
predictions_train_3 = predict(model3, newdata = money_train_mod)

rmse1 = sqrt(mean(na.omit(predictions_train_1 - money_train_mod$TARGET_WINS)^2))
rmse2 = sqrt(mean(na.omit(predictions_train_2 - money_train_mod$TARGET_WINS)^2))
rmse3 = sqrt(mean(na.omit(predictions_train_3 - money_train_mod$TARGET_WINS)^2))

print(rmse1)
print(rmse2)
print(rmse3)

###Importing the evaluation dataset and transforming the data
evaluation = read_csv('https://raw.githubusercontent.com/Mattr5541/DATA-621-Homework-1/main/moneyball-training-data.csv')

money_train_join = money_train %>%
  mutate(train_or_test = 'train')

evaluation_join = evaluation %>%
  mutate(train_or_test = 'test')

df = rbind(subset(money_train_join, select =-TARGET_WINS), evaluation_join)

df <- df %>% 
  missMethods::impute_median() %>%
  filter(train_or_test == 'test')

df <- df %>% mutate(log_TEAM_FIELDING_E = log(TEAM_FIELDING_E))
df <- df %>% mutate(log_TEAM_PITCHING_H = log(TEAM_PITCHING_H))
df <- df %>% mutate(log_TEAM_PITCHING_BB = log(TEAM_PITCHING_BB))
df <- df %>% mutate(log_TEAM_PITCHING_SO = log(TEAM_PITCHING_SO))
df <- df %>% mutate(log_TEAM_BASERUN_SB = log(TEAM_BASERUN_SB))
df <- df %>% mutate(log_TEAM_BATTING_3B = log(TEAM_BATTING_3B))
df <- df %>% mutate(log_TEAM_BATTING_HR = log(TEAM_BATTING_HR))
df <- df %>% mutate(log_TEAM_BATTING_SO = log(TEAM_BATTING_SO))
df <- df %>% mutate(log_TEAM_BASERUN_CS = log(TEAM_BASERUN_CS))
df <- df %>% mutate(log_TEAM_FIELDING_DP = log(TEAM_FIELDING_DP))
df$log_TEAM_BASERUN_CS <- log(df$TEAM_BASERUN_CS + 1)
df$log_TEAM_BATTING_HR <- log(df$TEAM_BATTING_HR + 1)
df$log_TEAM_BATTING_SO <- log(df$TEAM_BATTING_SO + 1)
df$log_TEAM_BATTING_3B <- log(df$TEAM_BATTING_3B + 1)
df$log_TEAM_BASERUN_SB <- log(df$TEAM_BASERUN_SB + 1)
df$log_TEAM_PITCHING_SO <- log(df$TEAM_PITCHING_SO + 1)
df$log_TEAM_FIELDING_E <- log(df$TEAM_FIELDING_E + 1)
df$log_TEAM_PITCHING_BB <- log(df$TEAM_PITCHING_BB + 1)

###Making predictions for the evaluation data
predictions_1 = predict(model1, newdata = df)

print(predictions_1)

predictions_2 = predict(model2, newdata = df)

print(predictions_2)

predictions_3 = predict(model3, newdata = df)

print(predictions_3)
```

